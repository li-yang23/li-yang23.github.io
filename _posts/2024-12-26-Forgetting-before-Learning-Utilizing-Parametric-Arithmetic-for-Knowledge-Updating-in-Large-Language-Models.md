---
title: F-learning方法论文阅读笔记
description: notes for llm unlearning paper ‘Forgetting before Learning-Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models’
tags:
  - ai-explanation
  - llm-unlearning
  - ACL 23
category: AI-safety llm
date: 2024-12-26
---
大型语言模型 (LLM) 的最新进展展示了其在文本理解和生成方面的卓越能力。然而，即使是更强大的 LLM 也容易从训练语料库中获取错误或过时的信息。直接使用包含新知识的数据进行二次微调可能会因新旧知识之间的冲突而无法有效更新知识。在本文中，我们提出了一种新的微调范式，称为 F-Learning（Forgetting before Learning），它使用参数算法来促进旧知识的遗忘和新知识的学习。在两个公开数据集上的实验结果表明，我们提出的 F-Learning 可以明显提高完全微调和 LoRA 微调的知识更新性能，在大多数情况下同时超越现有基线。此外，我们还发现通过减去 LoRA 的参数来忘记旧知识可以产生与减去完全微调的参数类似的效果，有时甚至会大大超过它。

## 本文的背景
大预言模型在文本里结合生成方面展示出了卓越的能力，但是依然受到训练数据中的不正确的知识的困扰。许多现实世界中的知识是不断更新的，导致大语言模型在训练的时候学到的知识可能会过时或者无效。因此大模型需要持续更新来确保自己的知识是正确的有效的。

## 本文研究的问题
知识编辑，如何让模型更加直接简单有效地更新自己学到的知识

## 已有方法为什么不行
当时的已有方法主要包括
+ 保留模型已有参数的方法，比如RAG，或者添加新的参数（向模型注入一小部分可训练的参数来表示新知识，同时冻结原来的模型参数）：比如添加一个新的轻量级的前馈网络来添加适合特定事实上下文的新参数以实现知识泛化；以及模型编辑器Transformer-Patcher，通过添加并训练一小部分transformer中的神经元来修改大模型中的错误信息。
+ 修改模型已有参数的方法，比如**微调**；或者**元学习**：通过根据训练有素的超网络的预测改变LLM的参数来更新LLM的知识；还有**定位编辑**：借助一些属性，根据特定知识定位参数和神经元，并修改它们以校正输出。

这些方法大部分都需要添加新的知识库，神经网络模块，或者模型参数，而这这在实践中很麻烦并且增加了推理消耗。本文希望找到一种基于微调的方法来高效地完成知识更新。

## 本文的方法

给定一个在旧知识的集合$$K_{old}\{(x_1,y_1), (x_2,y_2),...,(x_n,y_n)\}$$上训练的模型$$f_{\theta}$$，以及一个新知识的集合$$K_{new}\{(x_1,y_1^{new}), (x_2,y_2^{new}),...,(x_n,y_n^{new})\}$$，本文的目标是根据这个新知识的集合来更新原来的模型，得到新的模型$$f_{\theta^*}$$，这个目标可以描述为

$$
f_{\theta^*}(x_i)=\left\{
\begin{aligned}
y_i^{new}&\quad if\quad x_i\in N(x_i) \\
f_{\theta}(x_i)&\quad if\quad x_i\in other
\end{aligned}
\right.
$$

其中$$N(x_i)$$是输入和等价的相邻输入，也就是只更新范围内的知识的输出，而不影响范围外的知识。

知识更新的质量可以使用三个指标来衡量
+ 可靠性：衡量为更新模型在新知识上的平均准确度
+ 泛化性：新模型也应该更新等效邻居，通过在等效的邻居上采样的结果的平均准确度衡量
+ 局部性：新模型不应改变不相关示例的输出，通过在领域外知识上没有变化的预测的结果的比例来衡量

本文提出的F-learning方法一共包含两个步骤，可以用于全参数微调和参数高效微调。

**遗忘旧知识**

本文将模型的**知识参数**定义为微调前后参数的改变量，即

$$
\theta_{\Delta}=FT\{\theta, K\}-\theta
$$

于是，本文首先在旧知识上继续微调原模型，得到一个微调后的模型，然后用上面这个式子得到旧知识的知识参数

$$
\theta^{old}_{\Delta}=FT\{\theta, K_{old}\}-\theta
$$

然后从模型中减去这部分知识参数，达到遗忘旧知识的目的，得到遗忘后的模型权重$$\theta'$$

$$
\theta'=\theta-\lambda\theta_{\Delta}^{old}
$$

**学习新知识**

主要就是通过在新知识数据集上监督微调遗忘后的模型来注入新知识。

## 本文如何说明效果

本文使用了ZsRE和CounterFact数据集进行试验。ZsRE是一个问答数据集，利用反向翻译生成的问题改述作为等价邻域。CounterFact包含反事实数据。本文将数据集划分为旧知识和新知识两部分，主要就是同一个问题的不同回答，一个回答当作旧知识，一个回答当作新知识。

本文使用了微调方法（Full-FT，LoRA，FT-c）以及定位编辑方法（ROME，MEMIT）作为对比方法。使用Llama2-7b和GPT-2-XL作为基础模型。先在旧知识上微调训练了3个epoch，然后执行遗忘方法。使用贪心解码进行推理

观察到的实验结果：
+ ROME非常有效地保持了在领域外知识上的可用性，但同时在领域内知识上地表现和原模型差不多，说明基本没怎么修改知识
+ 全参数微调比LoRA能更有效地学习新知识
+ 先用LoRA遗忘，然后全参数微调能够非常有效地达到更新知识的效果
+ 减去全微调的知识参数（即通过全微调忘记旧知识）在某些情况下会完全破坏基础模型的核心功能
+ 时间上，定位编辑方法的速度非常慢（？），F-Learning方法的速度比微调要慢，因为要做两遍微调，但明显强于定位编辑方法
+ 在遗忘之后，数学推理上的能力出现了明显退化，考试，阅读理解，理论问答，常识推理等方面没出现这个问题（？）

## 可能的未来方向

ROME和MEMIT的效率都非常低，为什么？可能需要看一下细节
为什么数学推理能力会出现退化？
这个东西有没有可能进一步细化，现在还是做任务相关的遗忘，输入还是问答对，以及可能还是跟输入的数据的覆盖程度有关系？