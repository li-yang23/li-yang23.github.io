---
title: (NDSS23)"Machine Unlearning of Features and Labels"论文阅读笔记
description: notes for paper
tags: AI NDSS23
category: AI MachineUnlearning
date: 2023-11-02

# bibliography: 2023-11-02-xai.bib
---
## 论文概述

<!-- 研究了什么问题 -->
本文研究机器学习模型中特征和标签的遗忘问题，具体而言针对原来遗忘单独数据节点的低效和精度影响问题。

<!-- 为什么要研究这个问题 -->
机器学习已经成为数据驱动服务的主要工具，但如果底层模型无意中捕获训练数据中的敏感信息并将其泄露给用户，则会造成隐私问题。其次部分地区和组织的法规也要求允许用户从模型中删除一部分数据，作为遗忘权的一部分。因此需要方法来允许模型在尽量不丢失精确度的情况下遗忘某些数据，消除某些训练数据对于模型的影响。预训练过程的数据中可能包含某些不符合价值观和道德观的数据，这些数据的影响也需要从模型中去除。遗忘问题需要有选择性的复原一部分学习过程，因此与已有的对抗攻击和微调过程都不相同，无法直接应用。最直观的方法是删除训练数据后重新训练模型，但这成本很高，且只有在训练数据仍然可用时才能进行。

<!-- 原来研究成什么样了 -->
逐渐开始有工作研究如何进行遗忘问题，cao等人证明了很多模型都可以表示成封闭加法形式，从而证明了重新训练遗忘部分数据的可行性。已有方法可以从模型中去除掉特定数据节点对于模型的影响，主要方式是通过对数据集分片，然后在片上分别训练模型，最后进行汇总的方式限制重训范围。另一种方法是利用影响函数来度量数据节点对于模型的影响，并且使用特定的近似方式来遗忘数据节点。

<!-- 为什么需要你来研究 -->
基于分片的方式在需要遗忘的数据节点增多时效率衰减的很明显，并且两种方式目前都仅用于遗忘单一数据节点，并不处理遗忘特征和标签的情况。在仅指定标签或者特征时因为需要处理多个满足要求的数据节点所以效率和模型精度都会降低。

<!-- 提出的方法是什么样的，解决了什么 -->
从影响函数的角度提出了一个不用重新训练的遗忘方法。基本思想我称之为对冲法，就是生成一个对冲的（扰动）样本，然后在降低原数据样本权重的同时增加对冲样本的权重，从而消除原数据对模型的影响。数学语言描述对冲基本思想是

$$
\begin{aligned}
\theta_{\epsilon, Z\rightarrow\widetilde{Z}}^* &= argmin_{\theta}L(\theta;D)+\epsilon\sum_{\widetilde{z}\in\widetilde{Z}}\ell(\widetilde{z},\theta)-\epsilon\sum_{z\in Z}\ell(z,\theta) \\
\widetilde{z} &= (x+\delta_x, y+\delta_y)
\end{aligned}
$$

对冲样本的生成通过对原样本加入扰动来描述，重点在于利用扰动样本来替代了对原样本的重新训练，从而支持了对于更大规模的数据样本的遗忘。同时通过不同的扰动样本构成方式支持了对于特征和标签的遗忘。于是将遗忘的重训练问题变成了在已训练模型上的微调问题，就是找到一个更新项$$\Delta(Z,\widetilde{Z})$$，来对模型参数进行更新：

$$
\theta_{\epsilon, Z\rightarrow\widetilde{Z}}^*\approx\theta^*+\Delta(Z,\widetilde{Z})
$$

本文对于损失函数可微的模型设计了一阶更新方式，对于损失函数有可逆hessian矩阵设计了二阶更新方式。

$$
\Delta(Z,\widetilde{Z})=\begin{cases}
    -\tau(\sum_{\widetilde{z}\in\widetilde{Z}}\nabla_\theta\ell(\widetilde{z},\theta^*)-\sum_{z\in Z}\nabla_{\theta}\ell(z,\theta^*)) \quad first-roder \\
    -H_{\theta^*}^{-1}\left(\sum_{\widetilde{z}\in\widetilde{Z}}\nabla_{\theta}\ell(\widetilde{z},\theta^*)-\sum_{z\in Z}\nabla_{\theta}\ell(z,\theta^*)\right) \quad second-order
\end{cases}
$$

在考虑二阶导时一阶里面的$$\tau$$被消掉了。

同时可以注意到，对冲方法与重训方法有着根本的不同，对冲方法的基本逻辑还是对着两个样本进行同时训练，调整两个样本的权重来减少原始样本的影响。但在$$\epsilon=1$$之前，严格来说都无法认为原始数据的样本被消除了。本文对对冲的理论性能也进行了分析，得到了两个结论。

首先，对冲方法可以在模型表现上贴近重训方法，根据文中定理2，在概率密度上两者的区别会在一个很小的区间内：

$$
e^{-\epsilon}\leq\frac{f_{\mathit{U}}(\theta)}{f_{\mathit{A}(\theta)}}\leq e^{\epsilon}
$$

其次，通过定理3的讨论，给定一个具有有界梯度残差范数和隐私预算$$(\epsilon,\delta)$$的学习模型，可以校准学习结果$$b$$的概率分布来得到有保证的遗忘方法。

总结来说，通过理论分析，本文说明了通过对冲方法可以得到与重训方法效果类似的模型，即“几乎差不多的遗忘结果”。但有必要指出，这并不保证对冲方法将敏感信息遗忘干净了。