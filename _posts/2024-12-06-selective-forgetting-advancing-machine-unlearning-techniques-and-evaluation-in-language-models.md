---
title: SeUL论文阅读笔记
description: notes for llm unlearning paper ‘Selective Forgetting-Advancing Machine Unlearning Techniques and Evaluation in Language Models’
tags:
  - ai-explanation
  - llm-unlearning
category: AI
date: 2024-12-06
---
本文介绍了一种用于在语言模型中实现精确和选择性遗忘的新方法。与以前采用完全相反的训练目标的方法不同，这种方法旨在减轻对语言模型性能的不利影响，特别是在生成任务中。此外，还提出了两个创新的评估指标：敏感信息提取可能性 (S-EL) 和敏感信息记忆准确度 (S-MA)，旨在衡量敏感信息消除的有效性。为了加强遗忘框架，提出了一种注释敏感范围的有效方法，涉及在线和离线策略。在线选择机制利用语言概率分数来确保计算效率，而离线注释则需要基于大型语言模型 (LLM) 的强大两阶段过程。

## 本文的背景
神经模型是根据主要来自互联网的数据进行训练的，并且训练后的模型可能会永久“记住”训练数据中包含的个人或敏感信息。人们对神经网络泄露个人敏感数据的担忧日益加剧，特别是在语言模型取得突破之后，语言模型在数据生成方面表现出了令人难以置信的能力。同时，“被遗忘权”在许多国家都已立法，例如欧盟的《通用数据保护条例》（GDPR）和加拿大的PIPEDA隐私立法。该权利要求公司根据用户请求删除个人数据。此外，因为模型权重和数据之间的关系尚不清楚，虽然从后端数据库中删除数据很简单，但从神经模型中移除信息确没有这么简单。
## 本文要研究的问题
在使用梯度上升进行遗忘时，攻击者可以在敏感信息的样本中添加普通的内容，然后要求遗忘这个样本来破坏对普通信息的理解。

## 原来的方法为什么不行
原来的方法会对整个样本的token序列进行梯度上升，因此会将整个token序列里面的信息进行消除，所以只要在这个token序列里面注入普通信息，那也就可以破坏对于普通信息的记忆。

## 本文的方法是什么
提出了敏感跨度标注的自动在线和离线方法，两个新的指标来衡量对于敏感信息的移除效果，提出了一个更高精度的梯度上升方法来遗忘序列中的指定部分（span）。

**遗忘方法**

遗忘的基本设定不变，还是在一个数据集上训练出了一个语言模型，现在要遗忘这个训练集的一个子集。本文定义了遗忘跨度（span），将每个遗忘集中的样本中的一个序列子集作为要遗忘跨度：
$$
\begin{aligned}
\forall (x_1, x_2,...,x_T)\in D_f, s^x=(s_1,s_2,..,s_m), \\
s_i=(x_{j_i},x_{j_i+1},...,x_{j_i+\vert s_i\vert-1})
\end{aligned}
$$
然后在做梯度上升时仅对span中的内容的梯度进行上升，也就是仅优化span内的token的对数似然：
$$
\mathcal{L}_{UL}(A(D),x)=\sum_{s_j\in s^x}\sum_{t=j_i}^{j_i+\vert s_i\vert-1}\log(p_{\theta}(x_t\vert x_{<t}))
$$
**span自动标注方法**

在在线（online）阶段，本文假设隐私信息不是常识，即在训练集中应当不会频繁出现，所以模型应当对其具有比较高的困惑度。所以本文使用了困惑度来选择对应的span token
$$
Select(x,\alpha)=\{x_t\vert\log(p'_{\theta}(x_t\vert x_{<t}))<\alpha\}
$$
在离现（offline）阶段，本文使用了一个前向标注+反向验证的方法。
+ 在前向标注过程，本文利用大模型的上下文学习能力，调用大模型（GPT），给出敏感信息的定义和样本，然后要求大模型标注给定的文本。
+ 在反向验证过程，本文直接大模型之前标注出的隐私span，然后让大模型打分（0，1，2），最后过滤掉0分的span。

**遗忘效果验证标准**

本文提出了两种指标：敏感提取可能性（S-EL）和敏感记忆准确性（S-MA），来衡量敏感信息的遗忘程度，基本是在原来的提取相似性和记忆准确度的基础上做了精细化。

**敏感提取可能性**指使用不同长度的前缀生成的后缀中，n-gram分割的结果包含真实后缀的敏感信息span的平均概率。
$$
\begin{aligned}
S-OVL_n(a,b)&=\frac{\sum_{c\in n-grams(a)}\mathbb{1}\{(c\cap s^b)\neq\varnothing\land(c\cap s^b)\subseteq b\}}{\sum_{c\in n-grams(a)}\mathbb{1}\{(c\cap s^b)\neq\varnothing\}} \\
S-EL_n(x)&=\frac{\sum_{t=1}^{T-n}S-OVL(f_{\theta}(x_{<t}),x_{\geq t})}{T-n}
\end{aligned}
$$

**敏感记忆准确性**指在逐个token预测到敏感span时，预测的最大概率token是敏感span内的token的占比。
$$
S-MA(x)=\frac{\sum_{t=1}^T\mathbb{1}\{arg\max(p_{\theta}(\cdot\vert x_{<t}))=x_t\land x_t\in s^x\}}{\sum_{t=1}^T\mathbb{1}\{x_t\in s^x\}}
$$

## 本文怎么说明效果的
本文使用了前一篇工作[[2024-12-02-Knowledge unlearning for mitigating privacy risks in language models]]（KUL）相同的遗忘数据集。然后使用了8种不同的分类任务的数据集作为评估数据集，然后使用了本文提出的指标和原来的指标作为评估指标，为对话任务还使用了F1分数和困惑度分数。模型等和KUL一致，毕竟也使用了KUL作为对比方法。

遗忘敏感信息的表现上，本文方法普遍比对比方法要好。在原来的提取相似性和记忆准确度上和KUL达到的同等水平，但是在本文提出的S-EL和S-MA上获得的效果比KUL更好。

模型可用性上，在分类任务上SEUL方法和KUL基本一致，但是在对话任务上明显比KUL更好，可能因为SEUL的精细化遗忘方法更少地影响模型的泛化性能。

训练效率上，和对比方法基本相似，不会延长遗忘过程。此外，较小的语言模型在保持性能方面出现较低的稳定性。（这可能是因为较小的语言模型的神经元会编码更加复杂重叠的概念，使用本文方法依然会导致关联的信息被影响）。

本文将提出的在线和离线的敏感信息标注方法和人工以及NER方法进行了对比。人工方法比较严格，展现出较少的标注数量，而NER方法标注了很多span。在线方法倾向于标记更多的span，而离线方法与人工结果的匹配度最高。Case study说明NER主要从序列中提取潜在实体而不是敏感信息，在线和离线注释方法都成功注释了敏感信息。但在线方法可能引入不能准确表示敏感信息的额外span。

## 可能的未来方向
首先是单独的用于识别隐私信息的模型，通过人工标注一部分然后使用强化学习等方式微调模型，让模型自己就能识别其中的隐私信息，但难点可能在于隐私信息的动态变化和定义模糊，可能更适合于识别法律固定的那些隐私，比如PII之类的。

其次是在线标注方法假定了隐私数据不会出现很多次，但出现次数可能和隐私性没有太多关系，比如受版权保护信息，或者一些在指定范围内可以共享的信息（公司员工的联系方式，工位等），都有可能出现多次。但当主体发生变化时（版权到期，员工离职），这些信息都可能变成隐私信息。离线标注方法可能可以部分解决这类问题。

最后，本文说明可能单独的梯度上升方法坑不大......单独用方法已经不能作为一个足够的工作了。